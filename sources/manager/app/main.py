#!/usr/bin/env python3


"""
there are three types of workers, three modalities that we'll try to support:

## trusted workers in docker stack
id is generated by docker

## untrusted workers in fly.io machines
id and auth token generated in manager.

## untrusted workers connecting over public internet
These would be set up by user in frontend, id and auth token would be generated for each.

Any metadata like "org" can be looked up from the id.



"""



import logging
import os, sys
import threading
import time
from typing import Optional

sys.path.append(os.path.normpath(os.path.join(os.path.dirname(__file__), '../../common/libs/misc')))
from tasking import remoulade

from fastapi import FastAPI, Request

from app.isolated_worker import *
from app.untrusted_task import *
import app.manager_actors


log = logging.getLogger(__name__)
log.setLevel(logging.DEBUG)
log.addHandler(logging.StreamHandler(sys.stderr))



app = FastAPI(
	title="Robust API",
	summary="invoke accounting calculators and other endpoints",
)


@app.get("/", include_in_schema=False)
async def read_root():
	"""	hello world	"""
	return {"Hello": "World"}



@app.post("/worker/{worker_id}/heartbeat")
def post_heartbeat(worker_id: str, task_id: str = None):
	"""
	While worker is processing a task, it should take care to call /worker/{id}/heartbeat every minute. - it can also do this the whole time, even when there's no task.
	"""
	log.debug('heartbeat %s %s', worker_id, task_id)
	worker = get_worker(worker_id, last_seen=datetime.datetime.now())
	worker.last_reported_task = task_id
	worker.last_reported_task_ts = datetime.datetime.now()



@app.post("/worker/{worker_id}/messages")
async def post_messages(request: Request, worker_id: str, inmsg: dict):
	"""
	Hangs until a message is available. Worker calls this in a loop.
	
	Always at most one message in the queue. The messages are:
		"ping" - worker should respond with "pong"
		a task - worker should start processing the task, and when it's done submit task_result in next call to /worker/{id}/messages
	
	If the manager has been reset while worker is processing a task:
		* this task_result will be ignored, worker will go on to the next task.
		* the remoulade task will eventually get marked as failed.
	
	IF the worker has been reset while processing a task:
		manager detects this because it expects a task_result, but gets none. The remoulade task will be made to return with failure.
		
	It might be possible that a client issues two requests to /messages with some overlap. This might happen if the connection breaks or client disconnects, and immediately connects again (as it should), but the first request is still waiting on toworker.get(1).
	In this case, the message will be lost. This is the same as if the worker never connected back again.
	
	 Concievably, the events pushed here can be pushed multiple times, the client can invoke this multiple times, if a connection error occurs during handling
	 
	"""

	task_result = inmsg.get('task_result')
	worker_info = inmsg.get('worker_info')


	log.debug('')
	log.debug('')
	log.debug('')
	log.debug('/messages worker_id=%s task_result=%s', worker_id, task_result)

	worker = get_worker(worker_id, last_seen=datetime.datetime.now())

	outmsg = {}

	if task_result:
		outmsg |= on_task_result(worker=worker, result=task_result)
	else:
		if worker.task and worker.task_given_ts:
			time_since_task_sent_to_worker = datetime.datetime.now() - worker.task_given_ts
			#log.debug(f'{time_since_task_sent_to_worker=}')
			if time_since_task_sent_to_worker > datetime.timedelta(seconds=15):
				# grace period, because in the loop below, we may think that we sent a response with task, but the worker might have been already disconnected. But we only record task_given_ts the first time we relay the task, so, if a worker keeps disconnecting, we eventually ...do...something?
				log.warn(f"""{worker.id} should be working on {worker.
						 task_id} and sending heartbeats, but it's coming back without result... {time_since_task_sent_to_worker=}""")
				put_event(dict(type='worker_died', worker=worker))
		else:
			put_event(dict(type='worker_available', worker=worker))
			time.sleep(1)

	while not await request.is_disconnected():


		heartbeat(worker)


		#log.debug('id(workers)=%s', id(workers))
		log.debug(f'{len(workers)=}')
		#for _,v in workers.items():
		#	log.debug('worker %s', v)
		#log.debug('worker %s not disconnected', worker_id)


		log.debug(f'{len(pending_tasks)=}')
		for v in pending_tasks:
			log.debug('%s', v)


		if worker.task:
			log.debug('give task: %s', worker.task)
			if not worker.task_given_ts:
				worker.task_given_ts = datetime.datetime.now()
			return outmsg | dict(task=dict(id = worker.task.id, proc=worker.task.proc, args=worker.task.args, worker_options=worker.task.worker_options))


		log.debug('sleep')
		log.debug('')
		try:
			worker.handler_wakeup.get(timeout=10)
		except queue.Empty:
			pass
		

		# give some time for actors to relay the result, but then let's not keep the worker hanging around with result indefinitely, because it always timeouts first, and we never actually send him a message. So let's send him the ack.

		if not worker.task and task_result:
			log.debug(str(outmsg))
			return outmsg


	log.debug('hangup.')
	log.debug('')




def remoulade_thread():
	"""
	this is a copy of remoulade.__main__.start_worker that works inside a thread.
	Spawn a remoulade worker and periodically check if it's still running.
	"""
	logger = logging.getLogger('remoulade')

	broker = remoulade.get_broker()
	broker.emit_after("process_boot")

	# i'm afraid there isnt a good way to healthcheck manager in the same way that we healthcheck the (trusted) workers container. I mean, we could run two manager processes, and devise one worker to serve it....idk
	worker = remoulade.Worker(broker, queues=[os.environ['QUEUE']], worker_threads=12, prefetch_multiplier=1)
	worker.start()

	running = True
	while running and not shutdown_event.is_set():
		if worker.consumer_stopped or worker.worker_stopped:
			running = False
			logger.info("Worker thread is not running anymore, stopping Worker.")
		else:
			time.sleep(1)

	worker.stop(5 * 1000)
	broker.emit_before("process_stop")
	broker.close()



print(threading.Thread(target=remoulade_thread, daemon=True).start())
print(threading.Thread(target=synchronization_thread, daemon=True).start())




# @app.on_event("startup")
# async def startup_event():
#     # Start the background thread
#     threading.Thread(target=background_task, daemon=True).start()

@app.on_event("shutdown")
async def shutdown():
	shutdown_event.set()
	events.put(dict(type='nop'))
	
