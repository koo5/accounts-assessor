#!/usr/bin/env python3


"""
there are three types of workers, three modalities that we'll try to support:

## trusted workers in docker stack
id is generated by docker

## untrusted workers in fly.io machines
id and auth token generated in manager.

## untrusted workers connecting over public internet
These would be set up by user in frontend, id and auth token would be generated for each.

Any metadata like "org" can be looked up from the id.



"""



import logging
import os, sys
import queue
import threading
import time
from collections import defaultdict

from remoulade import get_broker, Worker
sys.path.append(os.path.normpath(os.path.join(os.path.dirname(__file__), '../../common/libs/misc')))
from tasking import remoulade

from fastapi import FastAPI, Request, File, UploadFile, HTTPException, Form, status, Query, Header
from manager import *

app = FastAPI(
	title="Robust API",
	summary="invoke accounting calculators and other endpoints",
)



@app.post("/worker/{id}/heartbeat")
def heartbeat(id: str):
	"""
	While worker is processing a job, it should take care to call /worker/{id}/heartbeat every minute. - it can also do this the whole time, even when there's no job.
	"""
	events.push(dict(type='heartbeat', worker=get_worker(id), ts=time.now()))


@app.post("/worker/{id}/messages")
def messages(id: str, job_result=None):
	"""	Hangs until a message is available. Worker calls this in a loop.
	 the messages are:
	 "ping" - worker should respond with "pong"
	 "job" - worker should start processing the job, and when it's done do one of:
	 	* call /worker/{id}/result
	 	* submit job_result in next call to /worker/{id}/messages
	"""
	worker = get_worker(id)
	events.push(dict(type='heartbeat', worker=worker, ts=time.now()))
	if job_result:
		events.push(dict(type='job_result', worker=worker, result=job_result))
	return(worker.toworker.pop())


@app.post("/worker/{id}/job_result")
def job_result(id: str, job_result):
	""" Worker calls this when it's done with a job. """
	worker = get_worker(id)
	events.push(dict(type='heartbeat', worker=worker, ts=time.now()))
	events.push(dict(type='job_result', worker=worker, result=job_result))




# not sure how to compose this cleanly. We dont want fronted to import the whole queueing shebang.
import manager_actors
manager_actors.do_job = do_job



def start_worker2():
	"""
	this is a copy of remoulade.__main__.start_worker that works inside a thread
	"""
	logger = logging.getLogger('remoulade')

	broker = get_broker()
	broker.emit_after("process_boot")

	worker = Worker(broker, queues=['default'], worker_threads=1, prefetch_multiplier=1)
	worker.start()

	running = True
	while running:
		if worker.consumer_stopped:
			running = False
		if worker.worker_stopped:
			running = False
			logger.info("Worker thread is not running anymore, stopping Worker.")
		else:
			time.sleep(1)

	worker.stop(5 * 1000)
	broker.emit_before("process_stop")
	broker.close()



print(threading.Thread(target=start_worker2, daemon=True).start())

